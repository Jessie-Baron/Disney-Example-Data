{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession as ps\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/26 10:32:00 WARN Utils: Your hostname, Jessies-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)\n",
      "23/06/26 10:32:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/26 10:32:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ffed408e4a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = ps.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  4.0,\n",
       "  'GFG1',\n",
       "  datetime.date(2000, 8, 1),\n",
       "  datetime.datetime(2000, 8, 1, 12, 0)),\n",
       " (2,\n",
       "  8.0,\n",
       "  'GFG2',\n",
       "  datetime.date(2000, 6, 2),\n",
       "  datetime.datetime(2000, 6, 2, 12, 0)),\n",
       " (3,\n",
       "  5.0,\n",
       "  'GFG3',\n",
       "  datetime.date(2000, 5, 3),\n",
       "  datetime.datetime(2000, 5, 3, 12, 0))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([\n",
    "    (1, 4., 'GFG1', date(2000, 8, 1), datetime(2000, 8, 1, 12, 0)),\n",
    "    (2, 8., 'GFG2', date(2000, 6, 2), datetime(2000, 6, 2, 12, 0)),\n",
    "    (3, 5., 'GFG3', date(2000, 5, 3), datetime(2000, 5, 3, 12, 0))])\n",
    "\n",
    "rdd_df = spark.createDataFrame(rdd, schema=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/26 10:32:16 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "[Stage 4:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----------+-------------------+\n",
      "|  a|  b|   c|         d|                  e|\n",
      "+---+---+----+----------+-------------------+\n",
      "|  1|4.0|GFG1|2000-08-01|2000-08-01 12:00:00|\n",
      "|  2|8.0|GFG2|2000-06-02|2000-06-02 12:00:00|\n",
      "|  4|5.0|GFG3|2000-05-03|2000-05-03 12:00:00|\n",
      "+---+---+----+----------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ex_df = spark.createDataFrame([\n",
    "    Row(a=1, b=4., c='GFG1', d=date(2000, 8, 1),\n",
    "        e=datetime(2000, 8, 1, 12, 0)),\n",
    "   \n",
    "    Row(a=2, b=8., c='GFG2', d=date(2000, 6, 2),\n",
    "        e=datetime(2000, 6, 2, 12, 0)),\n",
    "   \n",
    "    Row(a=4, b=5., c='GFG3', d=date(2000, 5, 3),\n",
    "        e=datetime(2000, 5, 3, 12, 0))\n",
    "])\n",
    "\n",
    "ex_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----------+-------------------+\n",
      "|  a|  b|   c|         d|                  e|\n",
      "+---+---+----+----------+-------------------+\n",
      "|  1|4.0|GFG1|2000-08-01|2000-08-01 12:00:00|\n",
      "|  2|8.0|GFG2|2000-06-02|2000-06-02 12:00:00|\n",
      "|  3|5.0|GFG3|2000-05-03|2000-05-03 12:00:00|\n",
      "+---+---+----+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex_df2 = spark.createDataFrame([\n",
    "    (1, 4., 'GFG1', date(2000, 8, 1),\n",
    "     datetime(2000, 8, 1, 12, 0)),\n",
    "   \n",
    "    (2, 8., 'GFG2', date(2000, 6, 2),\n",
    "     datetime(2000, 6, 2, 12, 0)),\n",
    "   \n",
    "    (3, 5., 'GFG3', date(2000, 5, 3),\n",
    "     datetime(2000, 5, 3, 12, 0))\n",
    "], schema='a long, b double, c string, d date, e timestamp')\n",
    "\n",
    "ex_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "|      _c0|   _c1|       _c2|                 _c3|                 _c4|                _c5|\n",
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "|Review_ID|Rating|Year_Month|   Reviewer_Location|         Review_Text|             Branch|\n",
      "|670772142|     4|    2019-4|           Australia|If you've ever be...|Disneyland_HongKong|\n",
      "|670682799|     4|    2019-5|         Philippines|Its been a while ...|Disneyland_HongKong|\n",
      "|670623270|     4|    2019-4|United Arab Emirates|Thanks God it was...|Disneyland_HongKong|\n",
      "|670607911|     4|    2019-4|           Australia|HK Disneyland is ...|Disneyland_HongKong|\n",
      "|670607296|     4|    2019-4|      United Kingdom|the location is n...|Disneyland_HongKong|\n",
      "|670591897|     3|    2019-4|           Singapore|Have been to Disn...|Disneyland_HongKong|\n",
      "|670585330|     5|    2019-4|               India|Great place! Your...|Disneyland_HongKong|\n",
      "|670574142|     3|    2019-3|            Malaysia|Think of it as an...|Disneyland_HongKong|\n",
      "|670571027|     2|    2019-4|           Australia|Feel so let down ...|Disneyland_HongKong|\n",
      "|670570869|     5|    2019-3|               India|I can go on talki...|Disneyland_HongKong|\n",
      "|670443403|     5|    2019-4|       United States|Disneyland never ...|Disneyland_HongKong|\n",
      "|670435886|     5|    2019-4|              Canada|We spent the day ...|Disneyland_HongKong|\n",
      "|670376905|     4|    2019-4|           Australia|We spend two days...|Disneyland_HongKong|\n",
      "|670324965|     5|    2019-4|         Philippines|It was indeed the...|Disneyland_HongKong|\n",
      "|670274554|     5|    2018-9|           Australia|This place is HUG...|Disneyland_HongKong|\n",
      "|670205135|     3|    2019-1|      United Kingdom|We brought ticket...|Disneyland_HongKong|\n",
      "|670199487|     4|    2019-4|     Myanmar (Burma)|Its huge , not en...|Disneyland_HongKong|\n",
      "|670129921|     3|    2019-4|      United Kingdom|Around   60 per p...|Disneyland_HongKong|\n",
      "|670099231|     4|    2019-4|           Australia|It   s Disneyland...|Disneyland_HongKong|\n",
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./DisneylandReviews.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "|Review_ID|Rating|Year_Month|   Reviewer_Location|         Review_Text|             Branch|\n",
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "|Review_ID|Rating|Year_Month|   Reviewer_Location|         Review_Text|             Branch|\n",
      "|670772142|     4|    2019-4|           Australia|If you've ever be...|Disneyland_HongKong|\n",
      "|670682799|     4|    2019-5|         Philippines|Its been a while ...|Disneyland_HongKong|\n",
      "|670623270|     4|    2019-4|United Arab Emirates|Thanks God it was...|Disneyland_HongKong|\n",
      "|670607911|     4|    2019-4|           Australia|HK Disneyland is ...|Disneyland_HongKong|\n",
      "|670607296|     4|    2019-4|      United Kingdom|the location is n...|Disneyland_HongKong|\n",
      "|670591897|     3|    2019-4|           Singapore|Have been to Disn...|Disneyland_HongKong|\n",
      "|670585330|     5|    2019-4|               India|Great place! Your...|Disneyland_HongKong|\n",
      "|670574142|     3|    2019-3|            Malaysia|Think of it as an...|Disneyland_HongKong|\n",
      "|670571027|     2|    2019-4|           Australia|Feel so let down ...|Disneyland_HongKong|\n",
      "|670570869|     5|    2019-3|               India|I can go on talki...|Disneyland_HongKong|\n",
      "|670443403|     5|    2019-4|       United States|Disneyland never ...|Disneyland_HongKong|\n",
      "|670435886|     5|    2019-4|              Canada|We spent the day ...|Disneyland_HongKong|\n",
      "|670376905|     4|    2019-4|           Australia|We spend two days...|Disneyland_HongKong|\n",
      "|670324965|     5|    2019-4|         Philippines|It was indeed the...|Disneyland_HongKong|\n",
      "|670274554|     5|    2018-9|           Australia|This place is HUG...|Disneyland_HongKong|\n",
      "|670205135|     3|    2019-1|      United Kingdom|We brought ticket...|Disneyland_HongKong|\n",
      "|670199487|     4|    2019-4|     Myanmar (Burma)|Its huge , not en...|Disneyland_HongKong|\n",
      "|670129921|     3|    2019-4|      United Kingdom|Around   60 per p...|Disneyland_HongKong|\n",
      "|670099231|     4|    2019-4|           Australia|It   s Disneyland...|Disneyland_HongKong|\n",
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = df.withColumnRenamed('_c0', 'Review_ID'\n",
    "                              ).withColumnRenamed('_c1', 'Rating'\n",
    "                              ).withColumnRenamed('_c2', 'Year_Month'\n",
    "                              ).withColumnRenamed('_c3', 'Reviewer_Location'\n",
    "                              ).withColumnRenamed('_c4', 'Review_Text'\n",
    "                              ).withColumnRenamed('_c5', 'Branch')\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+-----------------+-----------+------+\n",
      "|Review_ID|Rating|Year_Month|Reviewer_Location|Review_Text|Branch|\n",
      "+---------+------+----------+-----------------+-----------+------+\n",
      "|Review_ID|Rating|Year_Month|Reviewer_Location|Review_Text|Branch|\n",
      "+---------+------+----------+-----------------+-----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "row = df_new.where(df_new.Review_ID == 'Review_ID')\n",
    "row.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "|Review_ID|Rating|Year_Month|   Reviewer_Location|         Review_Text|             Branch|\n",
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "|670772142|     4|    2019-4|           Australia|If you've ever be...|Disneyland_HongKong|\n",
      "|670682799|     4|    2019-5|         Philippines|Its been a while ...|Disneyland_HongKong|\n",
      "|670623270|     4|    2019-4|United Arab Emirates|Thanks God it was...|Disneyland_HongKong|\n",
      "|670607911|     4|    2019-4|           Australia|HK Disneyland is ...|Disneyland_HongKong|\n",
      "|670607296|     4|    2019-4|      United Kingdom|the location is n...|Disneyland_HongKong|\n",
      "|670591897|     3|    2019-4|           Singapore|Have been to Disn...|Disneyland_HongKong|\n",
      "|670585330|     5|    2019-4|               India|Great place! Your...|Disneyland_HongKong|\n",
      "|670574142|     3|    2019-3|            Malaysia|Think of it as an...|Disneyland_HongKong|\n",
      "|670571027|     2|    2019-4|           Australia|Feel so let down ...|Disneyland_HongKong|\n",
      "|670570869|     5|    2019-3|               India|I can go on talki...|Disneyland_HongKong|\n",
      "|670443403|     5|    2019-4|       United States|Disneyland never ...|Disneyland_HongKong|\n",
      "|670435886|     5|    2019-4|              Canada|We spent the day ...|Disneyland_HongKong|\n",
      "|670376905|     4|    2019-4|           Australia|We spend two days...|Disneyland_HongKong|\n",
      "|670324965|     5|    2019-4|         Philippines|It was indeed the...|Disneyland_HongKong|\n",
      "|670274554|     5|    2018-9|           Australia|This place is HUG...|Disneyland_HongKong|\n",
      "|670205135|     3|    2019-1|      United Kingdom|We brought ticket...|Disneyland_HongKong|\n",
      "|670199487|     4|    2019-4|     Myanmar (Burma)|Its huge , not en...|Disneyland_HongKong|\n",
      "|670129921|     3|    2019-4|      United Kingdom|Around   60 per p...|Disneyland_HongKong|\n",
      "|670099231|     4|    2019-4|           Australia|It   s Disneyland...|Disneyland_HongKong|\n",
      "|670033848|     5|   2018-11|           Hong Kong|There is nothing ...|Disneyland_HongKong|\n",
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = df_new.filter(df_new.Review_ID >= 0)\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "|Review_ID|Rating|Year_Month|   Reviewer_Location|         Review_Text|             Branch|\n",
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "|670772142|     4|    2019-4|           Australia|If you've ever be...|Disneyland_HongKong|\n",
      "|670682799|     4|    2019-5|         Philippines|Its been a while ...|Disneyland_HongKong|\n",
      "|670623270|     4|    2019-4|United Arab Emirates|Thanks God it was...|Disneyland_HongKong|\n",
      "|670607911|     4|    2019-4|           Australia|HK Disneyland is ...|Disneyland_HongKong|\n",
      "|670607296|     4|    2019-4|      United Kingdom|the location is n...|Disneyland_HongKong|\n",
      "|670591897|     3|    2019-4|           Singapore|Have been to Disn...|Disneyland_HongKong|\n",
      "|670585330|     5|    2019-4|               India|Great place! Your...|Disneyland_HongKong|\n",
      "|670574142|     3|    2019-3|            Malaysia|Think of it as an...|Disneyland_HongKong|\n",
      "|670571027|     2|    2019-4|           Australia|Feel so let down ...|Disneyland_HongKong|\n",
      "|670570869|     5|    2019-3|               India|I can go on talki...|Disneyland_HongKong|\n",
      "|670443403|     5|    2019-4|       United States|Disneyland never ...|Disneyland_HongKong|\n",
      "|670435886|     5|    2019-4|              Canada|We spent the day ...|Disneyland_HongKong|\n",
      "|670376905|     4|    2019-4|           Australia|We spend two days...|Disneyland_HongKong|\n",
      "|670324965|     5|    2019-4|         Philippines|It was indeed the...|Disneyland_HongKong|\n",
      "|670274554|     5|    2018-9|           Australia|This place is HUG...|Disneyland_HongKong|\n",
      "|670205135|     3|    2019-1|      United Kingdom|We brought ticket...|Disneyland_HongKong|\n",
      "|670199487|     4|    2019-4|     Myanmar (Burma)|Its huge , not en...|Disneyland_HongKong|\n",
      "|670129921|     3|    2019-4|      United Kingdom|Around   60 per p...|Disneyland_HongKong|\n",
      "|670099231|     4|    2019-4|           Australia|It   s Disneyland...|Disneyland_HongKong|\n",
      "|670033848|     5|   2018-11|           Hong Kong|There is nothing ...|Disneyland_HongKong|\n",
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = df_new.filter(df_new.Year_Month.startswith('2'))\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleData = ((\"James\", \"Sales\", 3000), \\\n",
    "    (\"Michael\", \"Sales\", 4600),  \\\n",
    "    (\"Robert\", \"Sales\", 4100),   \\\n",
    "    (\"Maria\", \"Finance\", 3000),  \\\n",
    "    (\"James\", \"Sales\", 3000),    \\\n",
    "    (\"Scott\", \"Finance\", 3300),  \\\n",
    "    (\"Jen\", \"Finance\", 3900),    \\\n",
    "    (\"Jeff\", \"Marketing\", 3000), \\\n",
    "    (\"Kumar\", \"Marketing\", 2000),\\\n",
    "    (\"Saif\", \"Sales\", 4100) \\\n",
    "  )\n",
    " \n",
    "columns= [\"employee_name\", \"department\", \"salary\"]\n",
    "win_df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "provide a rank to the result within a window partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----------+\n",
      "|employee_name|department|salary|row_number|\n",
      "+-------------+----------+------+----------+\n",
      "|Maria        |Finance   |3000  |1         |\n",
      "|Scott        |Finance   |3300  |2         |\n",
      "|Jen          |Finance   |3900  |3         |\n",
      "|Kumar        |Marketing |2000  |1         |\n",
      "|Jeff         |Marketing |3000  |2         |\n",
      "|James        |Sales     |3000  |1         |\n",
      "|James        |Sales     |3000  |2         |\n",
      "|Robert       |Sales     |4100  |3         |\n",
      "|Saif         |Sales     |4100  |4         |\n",
      "|Michael      |Sales     |4600  |5         |\n",
      "+-------------+----------+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "win_df.withColumn(\"row_number\",f.row_number().over(windowSpec)) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cumulative distribution of values within a window partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+------------------+\n",
      "|employee_name|department|salary|         cume_dist|\n",
      "+-------------+----------+------+------------------+\n",
      "|        Maria|   Finance|  3000|0.3333333333333333|\n",
      "|        Scott|   Finance|  3300|0.6666666666666666|\n",
      "|          Jen|   Finance|  3900|               1.0|\n",
      "|        Kumar| Marketing|  2000|               0.5|\n",
      "|         Jeff| Marketing|  3000|               1.0|\n",
      "|        James|     Sales|  3000|               0.4|\n",
      "|        James|     Sales|  3000|               0.4|\n",
      "|       Robert|     Sales|  4100|               0.8|\n",
      "|         Saif|     Sales|  4100|               0.8|\n",
      "|      Michael|     Sales|  4600|               1.0|\n",
      "+-------------+----------+------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "win_df.withColumn(\"cume_dist\",f.cume_dist().over(windowSpec)) \\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|min(Year_Month)|\n",
      "+---------------+\n",
      "|        2010-10|\n",
      "+---------------+\n",
      "\n",
      "+---------------+\n",
      "|max(Year_Month)|\n",
      "+---------------+\n",
      "|         2019-5|\n",
      "+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_new.select(f.min(df_new.Year_Month)).show()\n",
    "df_new.select(f.max(df_new.Year_Month)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      avg(Rating)|\n",
      "+-----------------+\n",
      "|4.231101565816747|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.select(f.avg(df_new.Rating)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|max(Year_Month)|\n",
      "+---------------+\n",
      "|         2019-5|\n",
      "+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|min(Year_Month)|\n",
      "+---------------+\n",
      "|        2010-10|\n",
      "+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_new.select(f.max(df_new.Year_Month)).show()\n",
    "df_new.select(f.min(df_new.Year_Month)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Rating='3', count=4782),\n",
       " Row(Rating='5', count=21908),\n",
       " Row(Rating='1', count=1338),\n",
       " Row(Rating='4', count=10086),\n",
       " Row(Rating='2', count=1929)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.groupBy('Rating').count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670772142</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>670682799</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-5</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670623270</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670607911</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>670607296</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40038</th>\n",
       "      <td>92198076</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Although our pick up was prompt the taxi drive...</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40039</th>\n",
       "      <td>92061774</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Just returned from a 4 days family trip to Dis...</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40040</th>\n",
       "      <td>91995748</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>We spent the 20 Dec 2010 in the Disney park an...</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40041</th>\n",
       "      <td>91984642</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Well I was really looking forward to this trip...</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40042</th>\n",
       "      <td>91827418</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-9</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>If staying at a Disney hotel make good use of ...</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40043 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Review_ID Rating Year_Month     Reviewer_Location  \\\n",
       "0      670772142      4     2019-4             Australia   \n",
       "1      670682799      4     2019-5           Philippines   \n",
       "2      670623270      4     2019-4  United Arab Emirates   \n",
       "3      670607911      4     2019-4             Australia   \n",
       "4      670607296      4     2019-4        United Kingdom   \n",
       "...          ...    ...        ...                   ...   \n",
       "40038   92198076      4     2011-1        United Kingdom   \n",
       "40039   92061774      4     2011-1               Germany   \n",
       "40040   91995748      1    2010-12        United Kingdom   \n",
       "40041   91984642      2    2010-12        United Kingdom   \n",
       "40042   91827418      5     2010-9        United Kingdom   \n",
       "\n",
       "                                             Review_Text               Branch  \n",
       "0      If you've ever been to Disneyland anywhere you...  Disneyland_HongKong  \n",
       "1      Its been a while since d last time we visit HK...  Disneyland_HongKong  \n",
       "2      Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong  \n",
       "3      HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong  \n",
       "4      the location is not in the city, took around 1...  Disneyland_HongKong  \n",
       "...                                                  ...                  ...  \n",
       "40038  Although our pick up was prompt the taxi drive...     Disneyland_Paris  \n",
       "40039  Just returned from a 4 days family trip to Dis...     Disneyland_Paris  \n",
       "40040  We spent the 20 Dec 2010 in the Disney park an...     Disneyland_Paris  \n",
       "40041  Well I was really looking forward to this trip...     Disneyland_Paris  \n",
       "40042  If staying at a Disney hotel make good use of ...     Disneyland_Paris  \n",
       "\n",
       "[40043 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df = df_new.toPandas()\n",
    "pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/Users/jessiebaron/Documents/Disney-Example-Data/test.csv already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_new\u001b[39m.\u001b[39;49mwrite\u001b[39m.\u001b[39;49mcsv(\u001b[39m'\u001b[39;49m\u001b[39m./test.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py:1799\u001b[0m, in \u001b[0;36mDataFrameWriter.csv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode(mode)\n\u001b[1;32m   1781\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_opts(\n\u001b[1;32m   1782\u001b[0m     compression\u001b[39m=\u001b[39mcompression,\n\u001b[1;32m   1783\u001b[0m     sep\u001b[39m=\u001b[39msep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1797\u001b[0m     lineSep\u001b[39m=\u001b[39mlineSep,\n\u001b[1;32m   1798\u001b[0m )\n\u001b[0;32m-> 1799\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jwrite\u001b[39m.\u001b[39;49mcsv(path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/Users/jessiebaron/Documents/Disney-Example-Data/test.csv already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "df_new.write.csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "|Review_ID|Rating|Year_Month|   Reviewer_Location|         Review_Text|             Branch|\n",
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "|670772142|     4|    2019-4|           Australia|If you've ever be...|Disneyland_HongKong|\n",
      "|670682799|     4|    2019-5|         Philippines|Its been a while ...|Disneyland_HongKong|\n",
      "|670623270|     4|    2019-4|United Arab Emirates|Thanks God it was...|Disneyland_HongKong|\n",
      "|670607911|     4|    2019-4|           Australia|HK Disneyland is ...|Disneyland_HongKong|\n",
      "|670607296|     4|    2019-4|      United Kingdom|the location is n...|Disneyland_HongKong|\n",
      "|670591897|     3|    2019-4|           Singapore|Have been to Disn...|Disneyland_HongKong|\n",
      "|670585330|     5|    2019-4|               India|Great place! Your...|Disneyland_HongKong|\n",
      "|670574142|     3|    2019-3|            Malaysia|Think of it as an...|Disneyland_HongKong|\n",
      "|670571027|     2|    2019-4|           Australia|Feel so let down ...|Disneyland_HongKong|\n",
      "|670570869|     5|    2019-3|               India|I can go on talki...|Disneyland_HongKong|\n",
      "|670443403|     5|    2019-4|       United States|Disneyland never ...|Disneyland_HongKong|\n",
      "|670435886|     5|    2019-4|              Canada|We spent the day ...|Disneyland_HongKong|\n",
      "|670376905|     4|    2019-4|           Australia|We spend two days...|Disneyland_HongKong|\n",
      "|670324965|     5|    2019-4|         Philippines|It was indeed the...|Disneyland_HongKong|\n",
      "|670274554|     5|    2018-9|           Australia|This place is HUG...|Disneyland_HongKong|\n",
      "|670205135|     3|    2019-1|      United Kingdom|We brought ticket...|Disneyland_HongKong|\n",
      "|670199487|     4|    2019-4|     Myanmar (Burma)|Its huge , not en...|Disneyland_HongKong|\n",
      "|670129921|     3|    2019-4|      United Kingdom|Around   60 per p...|Disneyland_HongKong|\n",
      "|670099231|     4|    2019-4|           Australia|It   s Disneyland...|Disneyland_HongKong|\n",
      "|670033848|     5|   2018-11|           Hong Kong|There is nothing ...|Disneyland_HongKong|\n",
      "+---------+------+----------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.createOrReplaceTempView(\"Disney\")\n",
    "\n",
    "spark.sql('SELECT * FROM Disney').show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
